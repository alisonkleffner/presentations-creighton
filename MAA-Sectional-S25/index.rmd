---
title: "Visualization and Modeling of Sea Ice Trajectories"
subtitle: "MAA Sectional"
author: "Alison Kleffner"
date: "Department of Mathematics, Creighton University"
output:
  xaringan::moon_reader:
    seal: false
    includes:
      after_body:
        "js-addins.html"
    #mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: ["default", "metropolis-fonts", "metropolis" ,"css/modal.css", "css/sizeformat.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightlines: true
      countIncrementalSlides: true
---
class:title-slide-custom

```{r, child = "style.Rmd"}
```


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
# Packages
library(emoji)
library(purrr)
library(tidyverse)
library(gridExtra)
library(nullabor)
library(scales)
library(knitr)
library(kableExtra)
library(RefManageR)
library(fontawesome)
library(shiny)
# download_fontawesome()

# References
bib <- ReadBib("bib/thesis.bib", check = FALSE)
ui <- "- "

# R markdown options
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      cache = TRUE,
                      dpi = 300)
options(htmltools.dir.version = FALSE)
options(knitr.kable.NA = '')
```

```{r, include = F, eval = T, cache = T}
clean_file_name <- function(x) {
  basename(x) %>% str_remove("\\..*?$") %>% str_remove_all("[^[A-z0-9_]]")
}
img_modal <- function(src, alt = "", id = clean_file_name(src), other = "") {
  
  other_arg <- paste0("'", as.character(other), "'") %>%
    paste(names(other), ., sep = "=") %>%
    paste(collapse = " ")
  
  js <- glue::glue("<script>
        /* Get the modal*/
          var modal{id} = document.getElementById('modal{id}');
        /* Get the image and insert it inside the modal - use its 'alt' text as a caption*/
          var img{id} = document.getElementById('img{id}');
          var modalImg{id} = document.getElementById('imgmodal{id}');
          var captionText{id} = document.getElementById('caption{id}');
          img{id}.onclick = function(){{
            modal{id}.style.display = 'block';
            modalImg{id}.src = this.src;
            captionText{id}.innerHTML = this.alt;
          }}
          /* When the user clicks on the modalImg, close it*/
          modalImg{id}.onclick = function() {{
            modal{id}.style.display = 'none';
          }}
</script>")
  
  html <- glue::glue(
     " <!-- Trigger the Modal -->
<img id='img{id}' src='{src}' alt='{alt}' {other_arg}>
<!-- The Modal -->
<div id='modal{id}' class='modal'>
  <!-- Modal Content (The Image) -->
  <img class='modal-content' id='imgmodal{id}'>
  <!-- Modal Caption (Image Text) -->
  <div id='caption{id}' class='modal-caption'></div>
</div>
"
  )
  write(js, file = "js-addins.html", append = T)
  return(html)
}
# Clean the file out at the start of the compilation
write("", file = "js-addins.html")
```

<br><br><br>
## Visualization and Modeling of Sea Ice Trajectories
#### Alison Kleffner
#### Department of Mathematics, Creighton University

<br><br><br><br>
.medium[*Slides: https://alisonkleffner.github.io/presentations-creighton/MAA-Sectional-S25/index.html#1*]

---
class:primary
# General Motivation

The rapid development of technology, like global position systems (GPS) and geographic information systems (GIS), has led to a dramatic increase in the amount of spatial and spatio-temporal data collected `r Citep(bib[[c("ansari_spatiotemporal_2020")]])` 

+ This growth has necessitated the development of new techniques to work with this data `r Citep(bib[[c("yuan_review_2017")]])`

---
class:primary
# Motivation: Trajectories

**Interest**: Discover patterns within the trajectories to help understand their behavior and use these behaviors to reconstruct an underlying process.

  + Visualize trajectories to provide insight into the underlying dynamics driving movement.
  + Trajectories are complex, so we can extract features from the raw data `r Citep(bib[[c("climate-viz")]])` - Motivated by the visualization
  + Use the features and insights to inform modeling
  
.center[
```{r traj-ex,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/traj-example.png", alt = "Example of a Trajectory", other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]



**Case Study**: Arctic Sea Ice Crack Detection

???

Of common interest with trajectories is to discover patterns within their movements to help understand the trajectories behavior. One method to help discover these patterns is to visualize the trajectories during exploratory data analysis. These plots tend to messy due to the complexity of trajectories, but they can still provide some insight into the underlying dynamics driving movement. Since trajectories are complex, extracting features form them may make them easier to work within different methods. The features should summarize it's movement. Visualization can be used to motivate the creation of features. For example, Wu et al (2022) developed a method called TPoSTE which created features based on events to separate a boat's trajectory into period of fishing or sailing. For our process, we focus on a case study involving arctic sea ice trajectories.

---
class:primary

# Importance of Arctic Sea Ice Lead Detection

+ Sea ice serves as a barrier between the atmosphere and the ocean
+ Cracks, or leads, may form in the ice pack due to dynamic processes
  - Allows for heat from the ocean to be transferred to the atmosphere `r Citep(bib[[c("schreyer_elastic_2006")]])`. 
  - Accounts for half of the heat flux between the ocean and atmosphere `r Citep(bib[[c("badgley_1961")]])`

**Project Goals**:

- Develop a lead detection method by clustering similar trajectories
- Develop a model reconstructing the underlying process for interpolation

.center[
```{r ice-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/Ice Chunk.png", alt = " Artice Sea Ice with Crack", other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]



---
class:primary
# Data

.center[
```{r grid-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/rgps_grid.jpg", alt = "Example of initial grid used to track movement (Peterson & Sulsky, 2011)", other=list(width="25%"))
i2 <- img_modal(src = "images/data_example.png", alt = "Missing Data Oh My!", other=list(width="30%"))


c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]



+ Arctic Sea Ice is tracked by NASA's RADARSTAT Geophysical Processor System (RGPS), which uses synthetic aperture radar (SAR) images
+ Each grid cell vertex is assigned an identifier $(j=1,...,n)$ which is used for tracking
+ Set of all trajectories: 

.center[
$\mathcal{G} = \left\{g_1, ..., g_n\right\}$ $\\$
where $g_{j} = \left\{s_{jt} : t \in \mathcal{T}_j\right\}$, $\mathcal{T}_j \subset \left\{t=1...T\right\}$ a collection of time points where $g_j$ is observed $\\$
and ${s_{jt}}$ = $(x_{jt}, y_{jt})$
]

+ For our study region, $n$ = 8811, and $T$ = 22

???

The sea ice trajectories were tracked by NASA's RADARSTATE geophysical processor system (RGPS), which uses sequential synthetic aperture radar images to track the trajectory of point on an ice sheet. On the first day of the study period, a grid is put on the image, where each grid cell vertex is assigned an identifier (j) that is tracked over the study period using feature based and area based tracking. At the end of the study period we have a data set of n trajectories, where each trajectory is a collection of spatial locations at different times. Due to collecting this data with a satellite, not all the trajectories are observed on the same day, so we have a collection of possible times. We focused on the Beaufort region, so we have a total of 8811 trajectories on 22 possible days.

---
class:primary
# Gestalt Principles of Visual Perception

**Identifing Patterns**: Can use the gestalt principles of visual perception to process large amounts of data efficiently. 
+ Explains how humans naturally perceive objects and organize them in groups

.pull-left[
Principle of Similarity: group items that look similar .
  + Trajectories with similar shapes and orientations `r Citep(bib[[c("chalbi_gestalt")]])`
.center[  
```{r law-sim,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/law-sim.png", alt = "Example of gestalt law of similarity", other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]
].pull-right[
Principle of Common Fate: group objects that share a dynamic behavior
  + Affected by the same underlying processes `r Citep(bib[[c("chalbi_gestalt", "alais-gestalt-1998")]])` 
.center[
```{r law-fate,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/common-fate.png", alt = "Example of gestalt law of common fate", other=list(width="60%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]]

???

Before we look at visualizations of the trajectories used during EDA, I first wanted to talk about an important tool to help extract patterns. The gestalt principles of visual perception helps users process large amounts of data efficiently by explaining how humans naturally perceive objects and organize them into groups. There are multiple, but we are going to focus on three here. The principle of similarity says that people tend to group items that look similar. So we organize trajectories with similar shapes and orientations into groups. Second is the principle of common fate used with animated graphics. This principle says that people group objects that share a dynamic behavior, like a flock of birds, as this means those objects are potentially affected by the same underlying processes. 

---
class:primary

# Static Trajectory Plot


+ Line segments, with the direction of each trajectory denoted by an arrow at the end `r Citep(bib[[c("andrienko_supporting_2000")]])` 
  - Shows the displacement and direction over time.
+ This plot violates several guidelines for effective visualization
  - However, the principle of similarity helps a viewer easily group trajectories that look to move with a similar form in the same direction over time

.center[
```{r traj-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/traj_plot.png", alt = "Plot of id trajectories to show movement and directiction of movement", other=list(width="55%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

???

First, we created a static plot of all of our trajectories, which connected each observed location of a trajectory with a line segment, and an arrow was added to the end to show the ending direction of movement. So this plot shows the displacement and direction of each trajectory over time.This plot is messy and violates several principles of effective graphics. For example, it's cluttered (trajectories on top of each other), and the color has no meaning (was just used to help visually differentiate the different trajectories better). The coloring is potentially problematic due to the principle of similarity, a user may group all similarly colored trajectories and try to derive a relationship which would be inaccurate. However, using the principle of similarity is also helpful as we can see group of trajectories that look to move with a similar form in the same direction. These groups tend to occur in contiguous patches and stick out even though the plot is kind of a mess. So we can make an assumption, that the underlying process causing the sea ice to move changes based on the location. 

---
class:primary
# Animated Trajectory Plot

[Link](https://alisonkleffner.github.io/presentations-creighton/MAA-Sectional-S25/traj.html)

+ Shows the incremental progress of each trajectory over time
  - Plot the new location at each time step and connect the new observation with the previous through a line segment. 
+ New information:
  - See a trajectory speeding up or slowing down through the length of the added line segments. 
  - Associate a movement with a particular day
+ Using gestalt principle of common fate
  - Trajectories moving with a similar velocity in contiguous patches.

???

Another drawback of the static trajectory plot is the inability to associated different movements with a specific time. So don't learn things related to specific times, just total time. So we can create an animation of our movement. We chose to use animation as Griffin et al (2006) found that animated plots allows users to identify moving clusters easier than multiple juxtaposed static plots. In our animated plot, we showed the incremental process of each trajectory on each day by adding the movement for a day, represented by a line segment, to the previous days movement. Now we can see the trajectory speeding up and slowing down based on the length of added line segments. Further, we can associate a movement with a particular day, like what day a trajectory changes direction. Here we can use the principle of common fate to group trajectories moving with a similar velocity (direction/speed), which once again seems to occur in contiguous patches.

---
class:primary
# Deriving Numerical Features: Bounding Box

+ Bounding Box Features:

  - Length travel in x/y between the minimum and maximum location 
  - Length travel in x/y between latest and earliest observation 
  - Angle of movement (direction)
  - Amount of “wiggle”: arc length

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i2 <- img_modal(src = "images/bb_1.png", alt = "(a) Length travel in x/y between latest and earliest observation and (b) Direction", other=list(width="30%"))
i1 <- img_modal(src = "images/bb_2.png", alt = "Length travel in x/y between the minimum and maximum location", other=list(width="30%"))
i3 <- img_modal(src = "images/wiggle.png", alt = "Wiggle Calculation", other=list(width="30%"))


c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i3, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9],
  str_split(i3, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

???

After visually exploring the data during exploratory data analysis, we wanted to derive numerical features based on the visualizations. This was done by creating essentially a bounding box around each trajectory, which represents its movement over time. We can then calculate different features from this bounding box. First, we can find the distance between the maximum and minimum coordinates (total displacement). Second, this value may not always represent the first and last day of the time frame, so we also found the different between the latest and earliest observation (displacement in time). Finally, using the displacement in time, we found the angle that the trajectory moved over the time frame.

Next, besides the bounding box, we wanted to derive a numerical assessment of "wiggle", as this is something that can be seen but may be hard to quantify. How I began to think through this was by imaging we pulled a trajectory so that it was straight. Trajectories with more wiggle would be longer that those with less wiggle. Since each trajectory consists of observed points connected by line segments, I found the length of each line segment and added them all together (estimate of act length). So the trajectories with a higher total length are wigglier.

---
class:primary

#Clustering Using All Data - Comparison

+ Clustering algorithm to assign trajectories to groups of similar
movements 
+  Can compare our results with deformation data found using a kinematic crack algorithm calculated using the RGPS data `r Citep(bib[[c("peterson_evaluating_2011")]])`
  - Note that this image does not represent the true ice cracks, just the cracks determined by this method.

.center[
```{r all-comp-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/all-weeks-comp.png", alt = "Comparison of Our Results to a Kinematic Crack Algorithm", other=list(width="80%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]


---
class:primary
#Interpolate Missing Points

Want to reconstruct the underlying process of ocean movement (assumed Gaussian), where we simultaneously obtain the movement in $x$ (called $u$) and the movement in $y$ (called $v$) at time $t$.
+ The movements are added to the previous location to estimate the missing location
$$(\hat{u}_{t}, \hat{v}_{t}) + (x_{t-1}, y_{t-1}) = (\hat{x}_t, \hat{y}_t)$$


We elected to use the Integrated Nested Laplace Approximation (INLA) approach:
  + Computational benefits over other methods, as it focuses on models that can be expressed as latent Gaussian Markov Random Fields (GMRF)
  + Easily accounts for the spatio-temporal structure of the data during the inferential process `r Citep(bib[[c("spde-book")]])`


???

We wanted to develop a model that reconstructs the assumed Gaussian underlying process, where we can jointly obtain the movement in x (called u) and the movement in y (called v) at time t. We can then add these movements to the previous location to estimate the missing location (explain the equation). We elected to use the integrated nested laplace approximation or INLA to create our models due to their compuational benefits over other methods since it focuses on models that can be expressed as latent gaussian markov random fields (see where later). Additionally, they provide flexibility to easily account for the spatio-temporal data during the underlying process. 

---
class:primary

#INLA: Continuously Indexed GF

Let's first begin by introducing a univariate process: $$\left\{H(s,t): s \in \mathcal{D} \subset \mathcal{R}^2, t \in \mathcal{R}\right\}$$ where there are $N$ spatial locations at $t$ time points.

The process is assumed Gaussian, where the model can be rewritten as 
$$H_{{i,t}} \sim N(\eta_{s,t}, \sigma^2_e)$$ 
with $\sigma^2_e$ representing the nugget effect and the linear predictor is defined as 

$$\eta_{i,t} = \alpha + Z(s,t)$$ 
with $\alpha$ denoting the intercept and the realization of the latent ST Gaussian Field (GF) is represented by $Z \sim GF(0,\Sigma)$ `r Citep(bib[[c("BLANGIARDO201333")]])`. 

???

To begin setting up our model, we can define out bivariate data by the joint process H, where we have n spatial locations at t time points. We assume the process is Gaussian so we can rewrite the model as $H_{{i,t}} \sim BivN(\eta_{i,t}, \sigma^2_e)$, where the sigma squared e represents the nugget effect (or measurement error) and our linear predictor eta is expressed as alpha, the intercept plus the realization of the latent spatio-temporal Gaussian field, w. The realization has a separable matern spatio temporal covariance function. 

---
class:primary

#INLA: SPDE

When working with point data, assuming a continuously indexed GF for $Z(s,t)$ is not a computationally efficient approach.

Instead used stochastic partial differential equations (SPDE)- represent a GF with Matern Covariance Function through a discretely indexed process called a GMRF `r Citep(bib[[c("spde-book")]])`
.pull-left[

.center[
```{r spde,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/mesh-ex.png", alt = "Example of the triangulation of a field used in our simulation study", other=list(width="90%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]].pull-right[
  
The linear predictor can then be rewritten as 
$$\eta_{i,t} = \alpha + \sum^{G}_{g=1}\tilde{A}_{ig}\tilde{Z_t}$$ 
where $\tilde{A}_{ig}$ is a sparse precision matrix mapping the GMRF, $\tilde{Z_t}$, to the $G$ nodes in the triangulation
]

???

When working with point data like our trajectories, assuming a continuously indexed gaussian field for w is not a computationally efficient approach. So instead we used stochastic partial differential equations. These represent a gaussian field with a matern covariance function through a discretely indexed process called a gaussian markov random field. To create the discrete index, a constrained delaunay triangulation. This triangluation prevents highly obtuse triangles, and we create triangles outside the boundary to prevent the variance being significantly higher at the boundary points (boundary effect). In this figure, an example of simulated data is given. On the right hand side is the data, which a blue line around the points to show the boundary. The left hand side shows the triangulation of this space, with the same blue line, where we see more triangles on the inside than outside. The density of the triangles also affects computation time.

Since we are using the stochastic partial differential equations, the linear predictors is rewritten, where we still have our intercept, but the A tilde is a sparse precision matrix that maps the GMRF, w, from the N locations in the data set to the G nodes in the triangulation. 

---
class:primary
#Final Model: Bivariate Process

We can represent $u$ and $v$ by the joint process $$\left\{B(s,t): s \in \mathcal{D} \subset \mathcal{R}^2, t \in \mathcal{R}\right\}$$

The process is assumed Gaussian, where the model can be rewritten as 
$$B_{{i,t}} \sim BiN(\eta_{i,t}, \sigma^2_e)$$ 

The linear predictor is written as
$$\eta_{it} = \alpha_u + \alpha_{v} + t + z_{u}(s) + z_{v}(s) + z_{uv}(s)$$

where $\alpha_u$ and $\alpha_{v}$ are the intercepts for each response and the $z$ functions represent the SPDE model for the $u$ and $v$ effects, along with their interaction.

---
class:primary
#Using Model

We developed a model within spatial-temporal neighbors to account for the non-stationary of our data

+ Due to observing most of the ice sheet every three days, our response in the model was the movement over three days, meaning 
$$(\hat{u}_{t}, \hat{v}_{t}) + (x_{t-3}, y_{t-3}) = (\hat{x}_t, \hat{y}_t)$$
+ Of the observed data within a group of spatial-temporal neighbors with a known location after three days, we randomly removed 10%

???

So for our final model to jointly measure u and v of the underlying process, we write the linear predictor as $\eta_{it} = \alpha_u + \alpha_{v} + z_{u}(s,t) + z_{v}(s,t) + z_{uv}(s,t)$, where we have our intercepts for each variable and the z functions represent the SPDE model for u and v spatio-temporal effects, along with their interaction. We developed a model within each intersection to account for the non-stationarity aspect of our data, using only data at time t, t-1, t+1. Only used three days as already computationally inefficient, and don't expect days further out to have much of an impact. 

Once we develop the model, we created a spatial grid that encompassed the sea ice to obtain values to use in our model (centroid of the grid cell). The underlying process should be smooth within an intersection, so the centroid should be close enough that it has a similar value of the underlying process. Once we create the grid for initial location estimates of the missing data, we used the developed bivariate model to find the predicted locations using the posterior mean of the linear predictor. The estimates are added to the previous day's known location to obtain the esimate of the missing location.

Now I'm going to walk through some of the results for our model using the sea ice trajectories. For testing, we created a model for each intersection and time combination. So if we had p intersections, which vary by week, and t time points, then t x p models are developed. Due to observing most of the ice sheet every three days, our response in the model was the movement over three days. Of the observed data in an intersection with a known location after three days, we randomly removed 10%. Then using the observed data, we fit the spatial model with a time fixed effect as it is computationally more efficient than the spatio-temporal model. Also, since we are only using three days to develop our model, there is probably not a significant amount of temporal dependence, as shown in the simulation study, where the spatial model sometimes performs better than the spatio-temporal model (for y). This model was used to estimate the underlying process that drives movement over three days.



---
class:primary
#Example Results - Week 1

.pull-left[

**RMSE for Interpolation Methods by cluster for Week 1**
```{r ice-results-tab2, message=FALSE, warning = FALSE}

result_data5 <- data.frame(Cluster = c(1,2,3,4,5,6), X1 = c(4.410,0.443,1.120,1.140,0.549, 1.320), Y1 = c(15.500, 0.870, 1.480, 1.980, 1.980, 2.970), X2 = c(1.330, 0.303, 1.770, 2.920, 0.969,2.330), Y2 = c(21.800, 0.527, 4.740, 3.420, 5.507, 7.450))

kableExtra::kable(result_data5, booktabs = TRUE, col.names = c( "Cluster", "X", "Y", "X", "Y"), escape = FALSE, align = "c", table.attr = "style='width:80%;'") %>% add_header_above(c(" ", "Joint Spatial" = 2, "Linear" = 2)) 

```
].pull-right[

**Coverage** 

A benefit of using a model-based approach is that we can determine the uncertainty of our estimate.
  - Use standard deviation of estimate computed using the posterior marginals, to compute intervals of our estimates. The intervals were used to find the proportion of intervals containing the true amount of movement

<br>

```{r ice-results-tab3, message=FALSE, warning = FALSE}

result_data6 <- data.frame(Week = c(1), X1 = c(0.389), Y1 = c(0.37))

kableExtra::kable(result_data6, booktabs = TRUE, col.names = c( "Week", "X", "Y"), escape = FALSE, align = "c", table.attr = "style='width:75%;'")
```

]


???

For time, I am just showing the RMSE results for Week 1. Once again, we are comparing it with linear interpolation. Overall our model seems to be performing better than linter interpolation. However, since each cluster is made of different movements we also Look at the RMSEs for each cluster, for x, in week 1, our model performs better than linear interpolation for cluster 3 through 6. The results for the y coordinate are similar, except in week 1, our model also performs better in cluster 1

A benefit of using a model-based approach is that we can determine the uncertainty of our estimate. Using the posterior marginals, we can find the standard deviation of the estimate, which can then be used to create an interval of our estimates. The intervals can then be used to find the proportion of intervals containing the true amount of movement during testing of our models, otherwise known as coverage. Our coverage is pretty low, which is some cause for concern. So there is maybe better priors to use in our inla model, or a better creation of the triangulation, etc. 



---
class:primary

# Discussion of Model


**Advantages**:

+ Takes into account the nonstationarity of the data
+ Showed some improvement, in terms of RMSE, over linear interpolation for curved data that is not highly sampled
+ Able to calculate uncertainty
  
**Areas for Improvement**:

+ Computational efficiency
+ Coverage shows that there is room for improvement with the prior specification
+ Combine into a one-step process

???

Our model is beneficial as it takes into account the non-stationarity of the data, which is an important component of this specific underlying process. And it Showed some improvement, in terms of RMSE, over linear interpolation for curved data that is not highly sampled. Also, it is able to estimate days on the edges, which linear interpolation is not able to do since it requires two observed locations to estimate in between. Finally we can calculate an uncertainty estimate of our predictions. 

Areas of improvement for our approach include computational efficiency. Due to develop t x p (number of intersections) models, it takes a long time to run (~20-45 minutes). Next, coverage showed there is room for improved with prior specification. Currently assuming the same prior for each model (more efficient), but probably not accurate.

  

---
class:primary
# References
<font size="1.5">
```{r, print_refs1, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("ansari_spatiotemporal_2020", "yuan_review_2017", "climate-viz", "schreyer_elastic_2006", "andrienko_supporting_2000", "spde-book", "peterson_evaluating_2011", "badgley_1961", "rinzivillo_visuallydriven_2008", "li-features", "chalbi_gestalt", "alais-gestalt-1998")]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```
</font>

